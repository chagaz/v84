---
title: Large Scale Empirical Risk Minimization via Truncated Adaptive Newton Method
abstract: Most second order methods are inapplicable to large scale empirical risk
  minimization (ERM) problems because both, the number of samples N and number of
  parameters p are large. Large N makes it costly to evaluate Hessians and large p
  makes it costly to invert Hessians. This paper propose a novel adaptive sample size
  second-order method, which reduces the cost of computing the Hessian by solving
  a sequence of ERM problems corresponding to a subset of samples and lowers the cost
  of computing the Hessian inverse using a truncated eigenvalue decomposition. Although
  the sample size is grown at a geometric rate, it is shown that it is sufficient
  to run a single iteration in each growth stage to track the optimal classifier to
  within its statistical accuracy. This results in convergence to the optimal classifier
  associated with the whole set in a number of iterations that scales with $\log(N)$.
  The use of a truncated eigenvalue decomposition result in the cost of each iteration
  being of order $p^2$. Theoretical performance gains manifest in practical implementations.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: eisen18a
month: 0
tex_title: Large Scale Empirical Risk Minimization via Truncated Adaptive Newton Method
firstpage: 1447
lastpage: 1455
page: 1447-1455
order: 1447
cycles: false
author:
- given: Mark
  family: Eisen
- given: Aryan
  family: Mokhtari
- given: Alejandro
  family: Ribeiro
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artificial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/eisen18a/eisen18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/eisen18a/eisen18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
