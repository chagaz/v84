---
title: Weighted Tensor Decomposition for Learning Latent Variables with Partial Data
abstract: Tensor decomposition methods are popular tools for learning latent variables
  given only lowerorder moments of the data. However, the standard assumption is that
  we have sufficient data to estimate these moments to high accuracy. In this work,
  we consider the case in which certain dimensions of the data are not always observed–common
  in applied settings, where not all measurements may be taken for all observations–resulting
  in moment estimates of varying quality. We derive a weighted tensor decomposition
  approach that is computationally as efficient as the non-weighted approach, and
  demonstrate that it outperforms methods that do not appropriately leverage these
  less-observed dimensions.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: gottesman18a
month: 0
tex_title: Weighted Tensor Decomposition for Learning Latent Variables with Partial
  Data
firstpage: 1664
lastpage: 1672
page: 1664-1672
order: 1664
cycles: false
author:
- given: Omer
  family: Gottesman
- given: Weiwei
  family: Pan
- given: Finale
  family: Doshi-Velez
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artificial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/gottesman18a/gottesman18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/gottesman18a/gottesman18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
