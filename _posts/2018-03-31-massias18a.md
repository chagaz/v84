---
title: Generalized Concomitant Multi-Task Lasso for Sparse Multimodal Regression
abstract: In high dimension, it is customary to consider Lasso-type estimators to
  enforce sparsity. For standard Lasso theory to hold, the regularization parameter
  should be proportional to the noise level, which is often unknown in practice. A
  remedy is to consider estimators such as the Concomitant Lasso, which jointly optimize
  over the regression coefficients and the noise level. However, when data from different
  sources are pooled to increase sample size, noise levels differ and new dedicated
  estimators are needed. We provide new statistical and computational solutions to
  perform heteroscedastic regression, with an emphasis on functional brain imaging
  with magneto- and electroencephalography (M/EEG). When instantiated to de-correlated
  noise, our framework leads to an efficient algorithm whose computational cost is
  not higher than for the Lasso, but addresses more complex noise structures. Experiments
  demonstrate improved prediction and support identification with correct estimation
  of noise levels.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: massias18a
month: 0
tex_title: Generalized Concomitant Multi-Task Lasso for Sparse Multimodal Regression
firstpage: 998
lastpage: 1007
page: 998-1007
order: 998
cycles: false
author:
- given: Mathurin
  family: Massias
- given: Olivier
  family: Fercoq
- given: Alexandre
  family: Gramfort
- given: Joseph
  family: Salmon
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artificial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/massias18a/massias18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/massias18a/massias18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
