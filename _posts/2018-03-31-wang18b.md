---
title: Regional Multi-Armed Bandits
abstract: We consider a variant of the classic multi-armed bandit problem where the
  expected reward of each arm is a function of an unknown parameter. The arms are
  divided into different groups, each of which has a common parameter. Therefore,
  when the player selects an arm at each time slot, information of other arms in the
  same group is also revealed. This regional bandit model naturally bridges the non-informative
  bandit setting where the player can only learn the chosen arm, and the global bandit
  model where sampling one arms reveals information of all arms. We propose an efficient
  algorithm, UCB-g, that solves the regional bandit problem by combining the Upper
  Confidence Bound (UCB) and greedy principles. Both parameter-dependent and parameter-free
  regret upper bounds are derived. We also establish a matching lower bound, which
  proves the order-optimality of UCB-g. Moreover, we propose SW-UCB-g, which is an
  extension of UCB-g for a non-stationary environment where the parameters slowly
  vary over time.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: wang18b
month: 0
tex_title: Regional Multi-Armed Bandits
firstpage: 510
lastpage: 518
page: 510-518
order: 510
cycles: false
author:
- given: Zhiyang
  family: Wang
- given: Ruida
  family: Zhou
- given: Cong
  family: Shen
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artificial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/wang18b/wang18b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/wang18b/wang18b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
