---
title: A Nonconvex Proximal Splitting Algorithm under Moreau-Yosida Regularization
abstract: We tackle highly nonconvex, nonsmooth composite optimization problems whose
  objectives comprise a Moreau-Yosida regularized term. Classical nonconvex proximal
  splitting algorithms, such as nonconvex ADMM, suffer from lack of convergence for
  such a problem class. To overcome this difficulty, in this work we consider a lifted
  variant of the Moreau-Yosida regularized model and propose a novel multiblock primal-dual
  algorithm that intrinsically stabilizes the dual block. We provide a complete convergence
  analysis of our algorithm and identify respective optimality qualifications under
  which stationarity of the original model is retrieved at convergence. Numerically,
  we demonstrate the relevance of Moreau-Yosida regularized models and the efficiency
  of our algorithm on robust regression as well as joint feature selection and semi-supervised
  learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: laude18a
month: 0
tex_title: A Nonconvex Proximal Splitting Algorithm under Moreau-Yosida Regularization
firstpage: 491
lastpage: 499
page: 491-499
order: 491
cycles: false
author:
- given: Emanuel
  family: Laude
- given: Tao
  family: Wu
- given: Daniel
  family: Cremers
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artificial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/laude18a/laude18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/laude18a/laude18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
