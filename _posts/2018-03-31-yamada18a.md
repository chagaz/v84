---
title: Post Selection Inference with Kernels
abstract: 'Finding a set of statistically significant features from complex data (e.g.,
  nonlinear and/or multi-dimensional output data) is important for scientific discovery
  and has a number of practical applications including biomarker discovery. In this
  paper, we propose a kernel-based post-selection inference (PSI) algorithm that can
  find a set of statistically significant features from non-linearly related data.
  Specifically, our PSI algorithm is based on independence measures, and we call it
  the Hilbert-Schmidt Independence Criterion (HSIC)-based PSI algorithm (hsicInf).
  The novelty of hsicInf is that it can handle non-linearity and/or multi-variate/multi-class
  outputs through kernels. Through synthetic experiments, we show that hsicInf  can
  find a set of  statistically significant features for both regression and classification
  problems. We applied hsicInf to real-world datasets and show that it can successfully
  identify important features. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: yamada18a
month: 0
tex_title: Post Selection Inference with Kernels
firstpage: 152
lastpage: 160
page: 152-160
order: 152
cycles: false
author:
- given: Makoto
  family: Yamada
- given: Yuta
  family: Umezu
- given: Kenji
  family: Fukumizu
- given: Ichiro
  family: Takeuchi
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artificial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/yamada18a/yamada18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/yamada18a/yamada18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
